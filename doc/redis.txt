1.cd /opt

2.mkdir redis

3.tar -zxvf redis-3.0.7.tar.gz

4.yum install -y gcc

5.cd /opt/redis/redis-3.0.7

6.make (如果出错make distclean)

7.make install

1.事务特性:A(原子性), C(一致性), I(隔离性), D(持久性)。

2.C(强一致性), A(高可用性), P(分区容错性)。

3.Redis:高性能的(key/value)分布式内存数据库。

    ./redis-cli -p 6379

    ping

    SHUTDOWN  (关闭redis服务器)

    exit (退出客户端)

./redis-benchmark (测试读写性能)

4.RDB:

    1)在指定的时间间隔内将内存中的数据集快照(Snapshot快照)写入磁盘,
    它恢复时是将快照文件直接读到内存里。

    2)Redis会单独fork一个子进程来进行持久化, 会先将数据写入到一个临时文件中, 待持久化过程都结束了, 再用这个临时文件替换上次持久化好的文件。
    整个过程中, 主进程是不进行任何IO操作的, 如果需要进行大规模数据的恢复, 且对于数据恢复的完整性不是非常敏感,那RDB方式要比AOF方式更加的高效。(fork的作用是复制一个与当前进程一样的进程。
    新进程的所有数据数值都和原进程一致, 并作为原进程的子进程)

    3)RDB的缺点是最后一次持久化后的数据可能丢失(意外宕机等等)。还有fork会产生2倍的内存膨胀空间, 并且大数据集fork也是非常耗时的。

    RDB默认频率:

        save 900 1     //十五分钟内改变一次
        save 300 10   //五分钟改变10次
        save 60 10000 // 一分钟改变1万次

    6)手动调用RDB备份==>BGSAVE

    7)RDB每次在fork子进程来执行RDB快照数据文件生成的时候, 如果数据文件特别大, 可能会导致对客户端提供的服务暂停数毫秒, 甚至数秒。

5.AOF:

    1)以日志的形式来记录每个写操作, 将Redis执行过的所有写指令记录下来(读操作不记录),
    redis重启时就会根据日志文件的内容将写指令从前到后执行一次以完成数据恢复工作。

    2)redis默认关闭AOF的功能。开启:

        appendonly yes

    3)RDB AOF的默认生成文件分别是:dump.rdb, appendonly.aof。(生成目录==>config get dir)

    4)AOF和RDB可以共存, AOF的优先级更高(恢复数据时, 有AOF就不走RDB了)

    5)若AOF文件所怀可以尝试修复==> # redis-check-aof --fix appendonly.aof

    6)appendfsync everysec 异步写入AOF(频率:每秒)效率较好。

      appendfsync always 发生数据改变会立即写进磁盘, 性能较差。数据完整性会更好。

    7)对于相同数据集的数据而言aof文件要远大于rdb文件, 恢复速度慢于rdb。
    AOF数据完整性保存较好, 但是频繁IO是它的致命问题, 所以被主从复制取代。

    8)AOF日志文件即使过大的时候, 出现后台重写操作, 也不会影响客户端的读写。

    9)AOF开启后, 支持的写QPS会比RDB支持的写QPS低。

6.性能建议:

    1)因为RDB文件只用作后备用途,建议只在Slave上持久化RDB文件,
    而且只要15分钟备份一次就够了,只保留save 900 1这条规则。

    2)如果不Enable AOF, 仅靠Master-Slave Replication 实现高可用性也可以。能省掉一大笔IO, 也减少了rewrite时带来的系统波动。
    代价是如果Master/Slave同时宕掉, 会丢失十几分钟的数据, 启动脚本也要比较两个Master/Slave中的RDB文件, 载入较新的那个。

使用缓存的原因:高性能、高并发。
    1)高性能:优化耗时查询。
    2)高并发:mysql单机支撑到2000QPS就差不多极限了。redis单机QPS可以轻松支撑几万。(内存天然就支撑高并发)

redis线程模型:
    1)redis内部使用文件事件处理器(file event handler), 这个文件事件处理器是单线程的, 所以redis才是单线程模型。
    它采用IO多路复用机制同时监听多个socket, 将产生事件的socket压入内存队列中, 事件分派器根据socket上的事件类型来选择对应的事件处理器进行处理。

    2)文件事件处理器的结构包含4个部分:
        *多个socket
        *IO多路复用程序
        *文件事件分派器
        *事件处理器(连接应答处理器、命令请求处理器、命令回复处理器)

    3)多个socket可能会并发产生不同的操作, 每个操作对应不同的文件事件, IO多路复用程序会监听多个socket, 会将产生事件的socket放入队列中排队,
    事件分派器每次从队列中取出一个socket, 根据socket的事件类型交给对应的事件处理器进行处理。

redis的一次通信过程:
    1)redis服务端进程初始化的时候, 会将server socket的AE_READABLE事件与连接应答处理器关联。

    2)客户端socket01向redis进程的server socket请求建立连接, 此时server socket会产生一个AE_READABLE事件, IO多路复用程序监听到server socket产生的事件后,
    将该socket压入队列中。文件事件分派器从队列中获取socket, 交给连接应答处理器。连接应答处理器会创建一个能与客户端通信的socket01,
    并将该socket01的AE_READABLE事件与命令请求处理器关联。

    3)此时客户端发送了一个set key value请求, 此时redis中的socket01会产生AE_READABLE事件, IO多路复用程序将socket01压入队列,
    此时事件分派器从队列中获取到socket01产生的AE_READABLE事件, 由于前面socket01的AE_READABLE事件已经与命令请求处理器关联,
    因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取socket01的key value并在内存中完成key value的设置。
    操作完成后, 它会将socket01的AE_WRITABLE事件与命令回复处理器关联。

    4)如果此时客户端准备好接收返回结果了, 那么redis中的socket01会产生一个AE_WRITABLE事件, 同样压入队列中, 事件分派器找到相关联的命令回复处理器,
    由命令回复处理器对socket01输入本次操作的一个结果(比如ok), 之后解除socket01的AE_WRITABLE事件与命令回复处理器的关联。

redis单线程模型也能效率这么高的原因:纯内存操作、核心是基于非阻塞的IO多路复用机制、单线程避免了多线程的频繁上下文切换问题, 预防了多线程可能产生的竞争问题、C语言实现, 距离操作系统更近。

redis数据类型:
    string:简单的KV缓存。
    hash:缓存对象(无嵌套)。
    list:有序列表, 粉丝列表、文章的评论列表, 队列, 分页查询。
    set:无序集合, 自动去重, 交集、并集、差集。
    sorted set:延时队列。

redis过期策略:定期删除 + 惰性删除。
    1)定期删除:redis默认是每隔100ms就随机抽取一些设置了过期时间的key, 检查其是否过期, 如果过期就删除。
    2)惰性删除:获取某个key的时候, redis会检查一下这个key, 如果设置了过期时间并且过期了就会删除, 不会返回任何东西。

如果定期删除漏掉了很多过期key, 然后你也没及时去查, 也就没走惰性删除, 大量过期key堆积在内存里, 导致redis内存块耗尽了,
那么走内存淘汰机制。

redis内存淘汰机制:
    1)noeviction:当内存不足以容纳新写入数据时, 新写入操作会报错。
    2)allkeys-lru:当内存不足以容纳新写入数据时, 在键空间中, 移除最近最少使用的key。
    3)allkeys-random:当内存不足以容纳新写入数据时, 在键空间中, 随机移除某个key。
    4)volatile-lru:当内存不足以容纳新写入数据时, 在设置了过期时间的键空间中, 移除最近最少使用的key。
    5)volatile-random:当内存不足以容纳新写入数据时, 在设置了过期时间的键空间中, 随机移除某个key。
    6)volatile-ttl:当内存不足以容纳新写入数据时, 在设置了过期时间的键空间中, 有更早过期时间的key优先移除。

redis实现高并发主要依靠主从架构, 一主多从, 一般来说, 很多项目其实就足够了, 单主用来写入数据, 单机几万QPS,
多从用来查询数据, 多个从实例可以提供每秒10w+的QPS。

如果想要在实现高并发的同时, 容纳大量的数据, 那么就需要redis集群, 使用redis集群之后, 可以提供每秒几十万的读写并发。

redis高可用, 如果是做主从架构部署, 那么加上哨兵就可以了, 任何一个实例宕机, 可以进行主备切换。

redis replication的核心机制:
    1)redis采用异步方式复制数据到slave节点。
    2)一个master node是可以配置多个slave node的。
    3)slave node也可以连接其他的slave node。
    4)slave node做复制的时候, 不会block master node的正常工作。
    5)slave node 在做复制的时候, 也不会block对自己的查询操作, 它会用旧的数据集来提供服务, 但是复制完成的时候, 需要删除旧数据集, 加载新数据集, 这个时候就会暂停对外服务了。
    6)slave node 主要用来进行横向扩容, 做读写分离, 扩容的slave node可以提高读的吞吐量。
    7)每次启动redis都会分配一个run id, 重启之后run id改变。
    8)repl-backlog-size 1mb:复制缓冲区大小, 部分复制的时候, 如果offset在这个范围内, 则开始部分复制, 否则全量复制。
    9)slave node内部有个定时任务, 每秒检查是否有新的master node要连接和复制, 如果发现, 就跟master node建立socket网络连接。

    10)master node将rdb快照文件发送给slave node, 如果rdb复制时间超过60秒(repl-timeout), 那么slave node就会认为复制失败,
    可以适当调大这个参数(对于千兆网卡的机器, 一般每秒传输100MB, 超过6G的文件, 很可能超过60s)

如果采用了主从架构, 那么建议必须开启master node的持久化, 不建议用slave node作为master node的数据热备, 如果你关掉master的持久化, 可能在master宕机重启的时候数据是空的,
然后可能一经过复制slave node的数据也丢了。另外, master的各种备份方案, 也需要做。万一本地的所有文件丢失了, 从备份中挑选一份rdb去恢复master, 这样才能确保启动的时候, 是有数据的,
即使采用了哨兵高可用机制, slave node可以自动接管master node, 但也可能sentinel还没检测到master failure, master node就自动重启了, 还是可能导致上面所有的slave node数据被清空。

redis主从复制的核心原理:
    1)当启动一个slave node的时候, 它会发送一个PSYNC命令给master node。
    由于是第一次复制, 不知道master的run id, 自然也不知道offset, 所以发送psync ? -1。

    2)触发一次full resynchronization全量复制。master收到请求, 发送master的run id给从节点。

    3)从节点slave保存master的信息。

    4)主节点bgsave保存rdb文件。

    5)主节点发送rdb文件。

    6)在4)和5)的这个过程中产生的数据, 会写到复制缓冲区中去。

    7)从节点清空原来的数据。

    8)从节点slave把rdb文件的数据装载进自身。

    9)主节点发送上面两个步骤产生的buffer到从节点slave。

    10)假设发生网络抖动或者别的情况, 暂时失去了连接。

    11)这个时候, master还在继续往buffer里面写数据。

    12)slave重新连接上了master。

    13)slave向master发送自己的offset和run id。

    14)master判断slave的offset是否在buffer的队列里面, 如果是, 那就返回continue给slave, 否则需要进行全量复制(因为这说明已经错过了很多数据了)。

    15)master发送从slave的offset开始到缓冲区队列结尾的数据给slave。

过期key处理:slave不会过期key, 只会等待master过期key。如果master过期了一个key, 或者通过LRU淘汰了一个key, 那么会模拟一条del命令发送给slave。

主从节点互相都会发送heartbeat信息。
master默认每隔10秒发送一次heartbeat, slave node每隔1秒发送一个heartbeat。

redis全量复制时机:
    1)redis slave首启动或者重启后, 连接master时。(master run id不存在/丢失)
    2)master重启时。(run id改变)

SLAVEOF 127.0.0.1 6379
info replication
SLAVEOF no one

Sentinel:
    port 26379
    // Sentinel去监视一个名为mymaster的主服务器, 这个主服务器的IP地址为127.0.0.1, 端口号为6379, 而将这个主服务器判断为失效至少需要2个Sentinel同意。
    sentinel monitor mymaster 127.0.0.1 6379 2
    // Sentinel认为服务器已经断线所需的毫秒数。
    sentinel down-after-milliseconds mymaster 30000
    // 在执行故障转移时, 最多可以有多少个从服务器同时对新的主服务器进行同步, 这个数字越小, 完成故障转移所需的时间就越长。从服务器在载入主服务器发来的RDB文件时,
    会造成从服务器在一段时间内不能处理命令请求。如果全部从服务器一起对新的主服务器进行同步, 那么就可能会造成所有从服务器在短时间内全部不可用的情况出现。
    sentinel parallel-syncs mymaster 1
    // 故障转移的超时时间。
    sentinel failover-timeout mymaster 180000

    1)监控:Sentinel会不断地检查你的主服务器和从服务器是否运作正常。

    2)当被监控的某个Redis服务器出现问题时, Sentinel可以通过API向管理员或者其他应用程序发送通知。

    3)当一个主服务器不能正常工作时, Sentinel会开始一次自动故障迁移操作, 它会将失效主服务器的其中一个从服务器升级为新的主服务器,
    并让失效主服务器的其他从服务器改为复制新的主服务器。当客户端试图连接失效的主服务器时, 集群也会向客户端返回新主服务器的地址,
    使得集群可以使用新主服务器代替失效服务器。

    4)Redis Sentinel是一个分布式系统, 你可以在一个架构中运行多个Sentinel进程, 这些进程使用流言协议(gossip protocols)来接收关于主服务器是否下线的信息,
    并使用投票协议(agreement protocols)来决定是否执行自动故障迁移, 以及选择哪个从服务器作为新的主服务器。

    5)一个Sentinel需要获得系统中多数(majority)Sentinel的支持, 才能发起一次自动故障迁移。

    6)如果服务器在给定的毫秒数之内, 没有返回Sentinel发送的PING命令的回复, 或者返回一个错误, 那么Sentinel将这个服务器标记为主观下线(SDOWN)。
    不过只有一个Sentinel将服务器标记为主观下线并不一定会引起服务器的自动故障迁移。只有在足够数量的Sentinel都将一个服务器标记为主观下线之后,
    服务器才会被标记为客观下线(ODOWN), 这时自动故障迁移才会执行。

    7)哨兵 + redis主从的部署架构, 是不保证数据零丢失的, 只能保证redis集群的高可用性。

    8)每个Sentinel以每秒钟一次的频率向它所知的主服务器、从服务器以及其他Sentinel实例发送一个PING命令。
    如果一个实例距离最后一次有效回复PING命令的时间超过down-after-milliseconds, 那么这个实例会被 Sentinel 标记为主观下线。

    9)哨兵互相之间的发现, 是通过redis的pub/sub系统实现的, 每个哨兵都会往__sentinel__:hello这个channel里发送一个消息, 这时候所有其他哨兵都可以消费到这个消息, 并感知到其他的哨兵的存在。
    每隔两秒钟, 每个哨兵都会往自己监控的某个master + slaves对应的__sentinel__:hello channel里发送一个消息, 内容是自己的host、ip和run id还有对这个master的监控配置。
    每个哨兵也会去监听自己监控的每个master + slaves对应的__sentinel__:hello channel, 然后去感知到同样在监听这个master + slaves的其他哨兵的存在。
    每个哨兵还会跟其他哨兵交换对master的监控配置, 互相进行监控配置的同步。

    10)quorum和majority:每次一个哨兵要做主备切换, 首先需要quorum数量的哨兵认为odown, 然后选举出一个哨兵来做切换, 这个哨兵还需要得到majority哨兵的授权, 才能正式执行切换。
    如果quorum < majority, 比如5个哨兵, majority就是3, quorum设置为2, 那么就3个哨兵授权就可以执行切换。
    但是如果quorum >= majority, 那么必须quorum数量的哨兵都授权, 比如5个哨兵, quorum是5, 那么必须5个哨兵都同意授权, 才能执行切换。

    11)configuration epoch:哨兵会对一套redis master + slaves进行监控, 有相应的监控的配置。
    执行切换的那个哨兵, 会从要切换到的新master(salve -> master)那里得到一个configuration epoch, 这就是一个version号, 每次切换的version号都必须是唯一的。
    如果第一个选举出的哨兵切换失败了, 那么其他哨兵, 会等待failover-timeout时间, 然后接替继续执行切换, 此时会重新获取一个新的configuration epoch, 作为新的version号。

缓存雪崩:避免key集中过期。使用本地缓存。使用限流技术保护mysql。
缓存穿透:将Null进行缓存。
缓存击穿:将热点数据设置为永不过期, 或使用分布式锁, 等待第一个请求构建完缓存之后, 再释放锁。

读的时候, 先读缓存, 缓存没有的话, 就读数据库, 然后取出数据后放入缓存, 同时返回响应。
更新的时候, 先更新数据库, 然后再删除缓存。

分布式寻址算法:
    1)hash算法:来了一个key, 首先计算hash值, 然后对节点数取模。然后打在不同的master节点上。
    一旦某一个master节点宕机, 所有请求过来, 都会基于最新的剩余master节点数去取模, 尝试去取数据。
    这会导致大部分的请求过来, 全部无法拿到有效的缓存, 导致大量的流量涌入数据库。

    2)一致性hash算法:一致性hash算法将整个hash值空间组织成一个虚拟的圆环, 整个空间按顺时针方向组织, 下一步将各个master节点(使用服务器的ip或主机名)进行hash。
    这样就能确定每个节点在其哈希环上的位置。
    来了一个key, 首先计算hash值, 并确定此数据在环上的位置, 从此位置沿环顺时针"行走", 遇到的第一个master节点就是key所在位置。
    在一致性哈希算法中, 如果一个节点挂了, 受影响的数据仅仅是此节点到环空间前一个节点(沿着逆时针方向行走遇到的第一个节点)之间的数据, 其它不受影响。增加一个节点也同理。
    但是, 一致性哈希算法在节点太少时, 容易因为节点分布不均匀而造成缓存热点的问题。为了解决这种热点问题, 一致性hash算法引入了虚拟节点机制, 即对每一个节点计算多个hash,
    每个计算结果位置都放置一个虚拟节点。这样就实现了数据的均匀分布, 负载均衡。

    3)redis cluster的hash slot算法:redis cluster有固定的16384个hash slot, 对每个key计算CRC16值, 然后对16384取模, 可以获取key对应的hash slot。
    redis cluster中每个master都会持有部分slot, 比如有3个master, 那么可能每个master持有5000多个hash slot。hash slot让node的增加和移除很简单,
    增加一个master, 就将其他master的hash slot移动部分过去, 减少一个master, 就将它的hash slot移动到其他master上去。移动hash slot的成本是非常低的。
    客户端的api, 可以对指定的数据, 让他们走同一个hash slot, 通过hash tag来实现。任何一台机器宕机, 其它节点不受影响。因为key找的是hash slot, 不是机器。

