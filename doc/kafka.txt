tar -zxvf zookeeper-3.4.13.tar.gz

cd zookeeper-3.4.13/conf

cp -p zoo_sample.cfg zoo.cfg

cd /opt/zookeeper/zookeeper-3.4.13/bin

./zkServer.sh start

cd /opt/kafka/

tar -zxvf kafka_2.12-2.1.0.tgz

cd /opt/kafka/kafka_2.12-2.1.0/bin

vim kafka-server-start.sh

    export KAFKA_HEAP_OPTS="-Xmx256m -Xms256m"

./kafka-server-start.sh -daemon ../config/server.properties

消息队列的核心:解耦、异步、削峰。
    1)解耦:A系统产生一条比较关键的数据, 很多系统都需要A系统将这个数据发送过来。
    2)异步:A系统接收一个请求, 需要在自己本地写库, 还需要在BCD三个系统写库。
    3)削峰:每秒5k个请求写入MQ, A系统每秒钟最多处理2k个请求。

RabbitMQ、RocketMQ、Kafka:
    1)单机吞吐量:RabbitMQ万级。RocketMQ、Kafka10万级, 支撑高吞吐。
    2)topic数量对吞吐量的影响:RocketMQ在同等机器下, 可以支撑大量的topic。Kafka在同等机器下尽量保证topic数量不要过多。
    3)时效性:RabbitMQ延迟最低。
    4)可用性:Kafka一个数据多个副本, 少数机器宕机, 不会丢失数据, 不会导致不可用。
    5)消息可靠性:RocketMQ、Kafka可以做到0丢失。

Kafka高可用:由多个broker组成, 创建一个topic, 这个topic可以划分为多个partition,
每个partition可以存在于不同的broker上, 每个partition存放一部分数据。(一个topic数据分散放在多个机器上)

每个partition的数据都会同步到其它机器上, 形成自己的多个replica副本。所有replica会选举一个leader出来, 那么生产和消费都跟这个leader打交道。
然后其他replica就是follower。写的时候, leader会负责把数据同步到所有follower上去, 读的时候就直接读leader上的数据即可。
Kafka会均匀地将一个partition的所有replica分布在不同的机器上, 这样才可以提高容错性。

如果某个broker宕机了, 这个broker上面的partition在其他机器上都有副本的, 如果这上面有某个partition的leader, 那么此时会从follower中重新选举一个新的leader出来。
大家继续读写那个新的leader即可。

写数据的时候, 生产者就写leader, 然后leader将数据落地写本地磁盘, 接着其他follower自己主动从leader来pull数据。一旦所有follower同步好数据了, 就会发送ack给leader。
leader收到所有follower的ack之后, 就会返回写成功的消息给生产者。

消费的时候, 只会从leader去读, 但是只有当一个消息已经被所有follower都同步成功返回ack的时候, 这个消息才会被消费者读到。

