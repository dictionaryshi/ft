es          db
index       数据库
type        数据表
document    一行数据

es可以将一个索引中的数据切分为多个shard, 分布在多台服务器上存储, 提升吞吐量和性能。

可以为每个shard创建多个replica副本, 保证es数据高可用。

es写数据过程:
    1)客户端选择一个node发送请求过去, 这个node就是coordinating node(协调节点)。
    2)coordinating node对document进行路由, 将请求转发给对应的node(有primary shard的node)。
    3)primary shard node处理请求, 然后将数据同步到replica node。
    4)coordinating node如果发现primary node和所有replica node都搞定之后, 就返回响应结果给客户端。

es读数据过程:
    1)客户端发送请求到任意一个node(coordinate node)。
    2)coordinate node对doc id进行哈希路由, 在primary shard以及其所有replica中随机选择一个。(负载均衡)
    3)接收请求的node返回document给coordinate node。
    4)coordinate node返回document给客户端。

es SearchType:
    1)query and fetch:向索引的所有shard都发出查询请求, 各分片返回的时候把document和计算后的排名信息(_score)一起返回。(性能最快, 排名不准, 查询量为用户查询量N * shard数)
    2)query then fetch:向所有shard发出请求, 各分片只返回文档id和_score, 然后按照各分片返回的文档的_score进行重新排序和排名, 取前N个文档。(性能一般, 排名不准, 查询量与用户要求一致)
    3)DFS query and fetch:在进行查询之前, 先对所有分片发送请求, 把所有分片中的词频和文档频率等打分依据全部汇总到一块。(性能一般, 排名准确, 查询量为用户查询量N * shard数)
    4)DFS query then fetch:比2)多一个DFS过程。(性能最差, 排名准确, 查询数据量准确)

es 搜索数据过程:
    1)客户端发送请求到一个coordinate node。
    2)协调节点将搜索请求转发到所有的shard上。(primary shard或replica shard)
    3)query phase:每个shard将自己的搜索结果(doc id)和_score返回给协调节点, 由协调节点进行数据的合并、排序、分页等操作, 产生最终结果。
    4)fetch phase:接着由协调节点根据doc id去各个节点上拉取实际的document数据, 最终返回给客户端。

es 写数据底层原理:
    1)先写入内存buffer, 同时将数据写入translog日志文件。在buffer里的时候数据是搜索不到的。
    如果buffer快满了, 或者到一定时间, 就会将内存buffer中的数据refresh到一个新的segment file中。(先进入os cache)
    每隔1秒钟, es将buffer中的数据写入一个新的segment file中, 每秒钟会产生一个新的磁盘文件segment file, 存储最近1秒内buffer中写入的数据。

    2)buffer中的数据被refresh操作刷入os cache中, 这个数据就可以被搜索到了。
    3)只要数据被输入到os cache中, buffer就会被清空。
    4)translog会变得越来越大, 最后触发commit操作。将buffer中现有数据refresh到os cache中去, 清空buffer。
    将一个commit point写入磁盘文件, 里面标识着这个commit point对应的所有segment file。
    强行将os cache中目前所有的数据都fsync到磁盘文件中去。最后清空现有translog日志文件, 重启一个translog, 此时commit/flush操作完成。
    默认30分钟自动执行一次flush, translog过大也会触发flush。refresh和flush都可以手动触发。

    5)translog也是先写入os cache, 默认每隔5秒刷一次到磁盘中去, 所以有5秒的数据, 停留在buffer、translog os cache、segment file os cache中, 所以会有5秒数据丢失的风险。
    6)数据写入segment file之后, 同时就建立好了倒排索引。
